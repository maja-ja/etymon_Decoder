import streamlit as st
import json
import random
DB_FILE = 'etymon_database.json'
# --- é é¢è¨­å®š ---
st.set_page_config(page_title="è©æ ¹å®‡å®™ï¼šè§£ç¢¼ AI å°èˆª", layout="wide")
def save_data(data):
    with open(DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)
# --- è®€å–æ•¸æ“š ---
@st.cache_data
def load_data():
    with open('etymon_database.json', 'r', encoding='utf-8') as f:
        return json.load(f)

data = load_data()

# --- å´é‚Šæ¬„ï¼šå°èˆªèˆ‡åˆ†é¡ ---
st.sidebar.title("ğŸš€ è©æ ¹å®‡å®™å°èˆª")
st.sidebar.markdown("---")

all_categories = [item['category'] for item in data]
selected_cat = st.sidebar.selectbox("é¸æ“‡çŸ¥è­˜é ˜åŸŸ", all_categories)

# é¡¯ç¤ºè©²å¤§é¡ä¸‹çš„æ‰€æœ‰è©æ ¹
current_cat_data = next(item for item in data if item['category'] == selected_cat)
st.sidebar.subheader(f"ğŸ“ {selected_cat}")
for group in current_cat_data['root_groups']:
    roots_display = " / ".join(group['roots'])
    st.sidebar.write(f"- {roots_display} ({group['meaning']})")

st.sidebar.markdown("---")
st.sidebar.info("é€™æ˜¯åˆ©ç”¨ AI å”ä½œé–‹ç™¼çš„èªç¾©è§£ç¢¼ç³»çµ±ï¼Œå°ˆæ³¨æ–¼é‚è¼¯å­¸ç¿’è€Œéæ­»èƒŒã€‚")

# --- ä¸»ä»‹é¢ ---
st.title("ğŸ§© Etymon Decoder èªæºè§£ç¢¼å™¨")
st.markdown(f"### ç•¶å‰æ¢ç´¢å€åŸŸï¼š`{selected_cat}`")

# æœå°‹åŠŸèƒ½
search_query = st.text_input("ğŸ” è¼¸å…¥å–®å­—æˆ–è©æ ¹ä¾†è§£ç¢¼...", placeholder="ä¾‹å¦‚: Predict, Bio, Port...")

# æœå°‹é‚è¼¯
if search_query:
    found = False
    query = search_query.lower()
    
    for cat in data:
        for group in cat['root_groups']:
            # æª¢æŸ¥è©æ ¹
            root_match = any(query in r.lower() for r in group['roots'])
            # æª¢æŸ¥å–®å­—
            words_match = [v for v in group['vocabulary'] if query in v['word'].lower()]
            
            if root_match or words_match:
                found = True
                with st.container():
                    st.divider()
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        st.markdown(f"### è©æ ¹: `{' / '.join(group['roots'])}`")
                        st.write(f"**æ ¸å¿ƒå«ç¾©:** {group['meaning']}")
                    with col2:
                        for v in group['vocabulary']:
                            # å¦‚æœæœå°‹å–®å­—ï¼Œç‰¹åˆ¥æ¨™è¨»è©²å–®å­—
                            is_target = query in v['word'].lower()
                            display_text = f"**{v['word']}** \nè§£æ§‹: `{v['breakdown']}`  \nå«ç¾©: {v['definition']}"
                            if is_target:
                                st.success(display_text)
                            else:
                                st.write(display_text)
    if not found:
        st.warning("æ‰¾ä¸åˆ°ç›¸é—œçµæœï¼Œè«‹å˜—è©¦å…¶ä»–é—œéµå­—ã€‚")

else:
    # é è¨­é¦–é å±•ç¤ºï¼šéš¨æ©Ÿæ¨è–¦
    st.write("è«‹å¾å·¦å´é¸æ“‡åˆ†é¡ï¼Œæˆ–åœ¨ä¸Šæ–¹æœå°‹ã€‚")
    st.info("ğŸ’¡ éš¨æ©Ÿæ¨è–¦ä¸€å€‹è©æ ¹å®¶æ—ï¼š")
    
    random_group = random.choice(current_cat_data['root_groups'])
    st.subheader(f"æœ¬ç«™æ¨è–¦ï¼š`-{' / '.join(random_group['roots'])}-` ({random_group['meaning']})")
    
    cols = st.columns(len(random_group['vocabulary'][:3]))
    for i, v in enumerate(random_group['vocabulary'][:3]):
        with cols[i]:
            st.metric(label=v['word'], value=v['definition'])
            st.caption(f"æ‹†è§£: {v['breakdown']}")
# --- ä»‹é¢ ---
st.set_page_config(page_title="è©æ ¹å®‡å®™ç®¡ç†å“¡", layout="wide")
tab1, tab2 = st.tabs(["ğŸ” è©æ ¹æœå°‹", "âš™ï¸ æ•¸æ“šç®¡ç†"])

data = load_data()

with tab1:
    st.title("ğŸ§© Etymon Decoder")
    # ... (ä¿ç•™ä½ ä¹‹å‰çš„æœå°‹é‚è¼¯ç¨‹å¼ç¢¼) ...
    st.info("è«‹åˆ° 'æ•¸æ“šç®¡ç†' åˆ†é æ›´æ–°ä½ çš„å–®å­—åº«")

with tab2:
    st.title("ğŸ›  æ•¸æ“šåº«æ‰‹å‹•æ›´æ–°")
    st.markdown("å°‡ Gemini ç”¢å‡ºçš„ JSON ä»£ç¢¼è²¼åœ¨ä¸‹æ–¹ï¼š")
    
    # é¡¯ç¤ºç›®å‰çš„ JSON æ–¹ä¾¿ä¿®æ”¹
    current_json_str = json.dumps(data, indent=4, ensure_ascii=False)
    new_json_str = st.text_area("JSON æ•¸æ“šå€", value=current_json_str, height=400)
    
    if st.button("ğŸ’¾ å„²å­˜ä¸¦æ›´æ–°è³‡æ–™åº«"):
        try:
            new_data = json.loads(new_json_str)
            save_data(new_data)
            st.success("è³‡æ–™åº«å·²æˆåŠŸæ›´æ–°ï¼è«‹é‡æ–°æ•´ç†é é¢ã€‚")
        except Exception as e:
            st.error(f"JSON æ ¼å¼æœ‰èª¤ï¼Œè«‹æª¢æŸ¥ï¼š{e}")
# --- å•†æ¥­åº•éƒ¨ (Call to Action) ---
st.markdown("---")
col_a, col_b, col_c = st.columns(3)
with col_a:
    st.button("ğŸ”“ è¨‚é–± API æ•¸æ“šæˆæ¬Š")
with col_b:
    st.button("ğŸ“˜ ç²å–å®Œæ•´ Notion æ¨¡æ¿")
with col_c:
    st.button("ğŸ’¬ è¯çµ¡å°ˆå®¶é–‹ç™¼")